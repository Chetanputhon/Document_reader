{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbFp7w4DB6HHSsHcwipHci",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chetanputhon/Document_reader/blob/main/Document_reader1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCvchGjHiUVI",
        "outputId": "32eb4855-d120-432d-c689-51277626272b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.47.1-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.12-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.7-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-docx\n",
            "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Collecting extract-msg\n",
            "  Downloading extract_msg-0.54.1-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.177.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.14.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Collecting pdfminer.six==20250506 (from pdfplumber)\n",
            "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250506->pdfplumber) (3.4.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250506->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Collecting olefile==0.47 (from extract-msg)\n",
            "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: tzlocal<6,>=4.2 in /usr/local/lib/python3.11/dist-packages (from extract-msg) (5.3.1)\n",
            "Collecting compressed-rtf<2,>=1.0.6 (from extract-msg)\n",
            "  Downloading compressed_rtf-1.0.7-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting ebcdic<2,>=1.1.1 (from extract-msg)\n",
            "  Downloading ebcdic-1.1.1-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: beautifulsoup4<4.14,>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from extract-msg) (4.13.4)\n",
            "Collecting RTFDE<0.2,>=0.1.1 (from extract-msg)\n",
            "  Downloading rtfde-0.1.2.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting red-black-tree-mod<=1.23,>=1.20 (from extract-msg)\n",
            "  Downloading red-black-tree-mod-1.22.tar.gz (34 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.25.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.48.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<4.14,>=4.11.1->extract-msg) (2.7)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.7.14)\n",
            "Collecting lark~=1.1.8 (from RTFDE<0.2,>=0.1.1->extract-msg)\n",
            "  Downloading lark-1.1.9-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting oletools>=0.56 (from RTFDE<0.2,>=0.1.1->extract-msg)\n",
            "  Downloading oletools-0.60.2-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.26.0)\n",
            "Collecting easygui (from oletools>=0.56->RTFDE<0.2,>=0.1.1->extract-msg)\n",
            "  Downloading easygui-0.98.3-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting colorclass (from oletools>=0.56->RTFDE<0.2,>=0.1.1->extract-msg)\n",
            "  Downloading colorclass-2.2.2-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting pcodedmp>=1.2.5 (from oletools>=0.56->RTFDE<0.2,>=0.1.1->extract-msg)\n",
            "  Downloading pcodedmp-1.2.6-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting msoffcrypto-tool (from oletools>=0.56->RTFDE<0.2,>=0.1.1->extract-msg)\n",
            "  Downloading msoffcrypto_tool-5.4.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.22)\n",
            "Downloading streamlit-1.47.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.12-py3-none-any.whl (26 kB)\n",
            "Downloading pdfplumber-0.11.7-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading extract_msg-0.54.1-py3-none-any.whl (335 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.0/336.0 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading compressed_rtf-1.0.7-py3-none-any.whl (8.0 kB)\n",
            "Downloading ebcdic-1.1.1-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.5/128.5 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rtfde-0.1.2.1-py3-none-any.whl (36 kB)\n",
            "Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lark-1.1.9-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading oletools-0.60.2-py2.py3-none-any.whl (989 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m989.4/989.4 kB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pcodedmp-1.2.6-py2.py3-none-any.whl (30 kB)\n",
            "Downloading colorclass-2.2.2-py2.py3-none-any.whl (18 kB)\n",
            "Downloading easygui-0.98.3-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.7/92.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msoffcrypto_tool-5.4.2-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.7/48.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: red-black-tree-mod\n",
            "  Building wheel for red-black-tree-mod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for red-black-tree-mod: filename=red_black_tree_mod-1.22-py3-none-any.whl size=19237 sha256=dd4f241b5e47b1079baaa87d357d4304d0623a96bf66d2af4aab48423f1c0f36\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/ae/7f/2933e7ea294e0f7e79b1b8cc304f89ad10886c8bb943b41003\n",
            "Successfully built red-black-tree-mod\n",
            "Installing collected packages: red-black-tree-mod, ebcdic, easygui, compressed-rtf, watchdog, python-docx, pypdfium2, pyngrok, olefile, lark, colorclass, pydeck, pdfminer.six, msoffcrypto-tool, pdfplumber, streamlit, pcodedmp, oletools, RTFDE, extract-msg\n",
            "Successfully installed RTFDE-0.1.2.1 colorclass-2.2.2 compressed-rtf-1.0.7 easygui-0.98.3 ebcdic-1.1.1 extract-msg-0.54.1 lark-1.1.9 msoffcrypto-tool-5.4.2 olefile-0.47 oletools-0.60.2 pcodedmp-1.2.6 pdfminer.six-20250506 pdfplumber-0.11.7 pydeck-0.9.1 pyngrok-7.2.12 pypdfium2-4.30.0 python-docx-1.2.0 red-black-tree-mod-1.22 streamlit-1.47.1 watchdog-6.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install google-generativeai streamlit pyngrok pdfplumber python-docx pandas openpyxl extract-msg\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install tesseract-ocr -y  # for Colab (Linux)\n",
        "!pip install pytesseract Pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuzR2cQ5ne2D",
        "outputId": "22d6e8bc-69a1-4399-d37d-c6f74a30e5c5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.3.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (25.0)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q google-generativeai\n"
      ],
      "metadata": {
        "id": "n1KKDbvUkhLt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyCzzRkrMsAblUY16Tk7yxWWr8JUB9hS45o\"  # Replace with your key"
      ],
      "metadata": {
        "id": "eZcf3oqkio0j"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "\n",
        "models = genai.list_models()\n",
        "\n",
        "for model in models:\n",
        "    print(f\"{model.name} | generation: {model.supported_generation_methods}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0pZc1JdZkm53",
        "outputId": "54e1152b-e897-4e01-afdf-0924929ee6e0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/embedding-gecko-001 | generation: ['embedText', 'countTextTokens']\n",
            "models/gemini-1.5-pro-latest | generation: ['generateContent', 'countTokens']\n",
            "models/gemini-1.5-pro-002 | generation: ['generateContent', 'countTokens', 'createCachedContent']\n",
            "models/gemini-1.5-pro | generation: ['generateContent', 'countTokens']\n",
            "models/gemini-1.5-flash-latest | generation: ['generateContent', 'countTokens']\n",
            "models/gemini-1.5-flash | generation: ['generateContent', 'countTokens']\n",
            "models/gemini-1.5-flash-002 | generation: ['generateContent', 'countTokens', 'createCachedContent']\n",
            "models/gemini-1.5-flash-8b | generation: ['createCachedContent', 'generateContent', 'countTokens']\n",
            "models/gemini-1.5-flash-8b-001 | generation: ['createCachedContent', 'generateContent', 'countTokens']\n",
            "models/gemini-1.5-flash-8b-latest | generation: ['createCachedContent', 'generateContent', 'countTokens']\n",
            "models/gemini-2.5-pro-preview-03-25 | generation: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.5-flash-preview-05-20 | generation: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.5-flash | generation: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.5-flash-lite-preview-06-17 | generation: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.5-pro-preview-05-06 | generation: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.5-pro-preview-06-05 | generation: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.5-pro | generation: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-exp | generation: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
            "models/gemini-2.0-flash | generation: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-001 | generation: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-exp-image-generation | generation: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
            "models/gemini-2.0-flash-lite-001 | generation: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-lite | generation: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-preview-image-generation | generation: ['generateContent', 'countTokens']\n",
            "models/gemini-2.0-flash-lite-preview-02-05 | generation: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-lite-preview | generation: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-pro-exp | generation: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-pro-exp-02-05 | generation: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-exp-1206 | generation: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-thinking-exp-01-21 | generation: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-thinking-exp | generation: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-thinking-exp-1219 | generation: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.5-flash-preview-tts | generation: ['countTokens', 'generateContent']\n",
            "models/gemini-2.5-pro-preview-tts | generation: ['countTokens', 'generateContent']\n",
            "models/learnlm-2.0-flash-experimental | generation: ['generateContent', 'countTokens']\n",
            "models/gemma-3-1b-it | generation: ['generateContent', 'countTokens']\n",
            "models/gemma-3-4b-it | generation: ['generateContent', 'countTokens']\n",
            "models/gemma-3-12b-it | generation: ['generateContent', 'countTokens']\n",
            "models/gemma-3-27b-it | generation: ['generateContent', 'countTokens']\n",
            "models/gemma-3n-e4b-it | generation: ['generateContent', 'countTokens']\n",
            "models/gemma-3n-e2b-it | generation: ['generateContent', 'countTokens']\n",
            "models/gemini-2.5-flash-lite | generation: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/embedding-001 | generation: ['embedContent']\n",
            "models/text-embedding-004 | generation: ['embedContent']\n",
            "models/gemini-embedding-exp-03-07 | generation: ['embedContent', 'countTextTokens', 'countTokens']\n",
            "models/gemini-embedding-exp | generation: ['embedContent', 'countTextTokens', 'countTokens']\n",
            "models/gemini-embedding-001 | generation: ['embedContent', 'countTextTokens', 'countTokens']\n",
            "models/aqa | generation: ['generateAnswer']\n",
            "models/imagen-3.0-generate-002 | generation: ['predict']\n",
            "models/imagen-4.0-generate-preview-06-06 | generation: ['predict']\n",
            "models/imagen-4.0-ultra-generate-preview-06-06 | generation: ['predict']\n",
            "models/veo-2.0-generate-001 | generation: ['predictLongRunning']\n",
            "models/veo-3.0-generate-preview | generation: ['predictLongRunning']\n",
            "models/veo-3.0-fast-generate-preview | generation: ['predictLongRunning']\n",
            "models/gemini-2.5-flash-preview-native-audio-dialog | generation: ['countTokens', 'bidiGenerateContent']\n",
            "models/gemini-2.5-flash-exp-native-audio-thinking-dialog | generation: ['countTokens', 'bidiGenerateContent']\n",
            "models/gemini-2.0-flash-live-001 | generation: ['bidiGenerateContent', 'countTokens']\n",
            "models/gemini-live-2.5-flash-preview | generation: ['bidiGenerateContent', 'countTokens']\n",
            "models/gemini-2.5-flash-live-preview | generation: ['bidiGenerateContent', 'countTokens']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
        "model = genai.GenerativeModel(\"models/gemini-2.0-flash\")\n",
        "\n",
        "def extract_structured_data_with_gemini(text):\n",
        "    prompt = f\"\"\"\n",
        "    Extract structured data in JSON format from the text below:\n",
        "\n",
        "    TEXT:\n",
        "    {text}\n",
        "    \"\"\"\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text\n"
      ],
      "metadata": {
        "id": "1B1tw1gTizaw"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pdfplumber\n",
        "from docx import Document\n",
        "import pandas as pd\n",
        "import extract_msg\n",
        "import os\n",
        "import google.generativeai as genai\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "\n",
        "def extract_text_from_image(file):\n",
        "    image = Image.open(file)\n",
        "    text = pytesseract.image_to_string(image)\n",
        "    return text\n",
        "\n",
        "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
        "model = genai.GenerativeModel(\"models/gemini-2.0-flash\")\n",
        "\n",
        "def extract_structured_data_with_gemini(text):\n",
        "    prompt = f\"\"\"\n",
        "    Extract structured data in JSON format from the text below:\n",
        "\n",
        "    TEXT:\n",
        "    {text}\n",
        "    \"\"\"\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text\n",
        "\n",
        "def extract_text_from_pdf(file):\n",
        "    with pdfplumber.open(file) as pdf:\n",
        "        return \"\\n\".join([page.extract_text() or \"\" for page in pdf.pages])\n",
        "\n",
        "def extract_text_from_docx(file):\n",
        "    doc = Document(file)\n",
        "    return \"\\n\".join([p.text for p in doc.paragraphs])\n",
        "\n",
        "def extract_text_from_excel(file):\n",
        "    df = pd.read_excel(file)\n",
        "    return df.to_string(index=False)\n",
        "\n",
        "def extract_text_from_msg(file):\n",
        "    msg = extract_msg.Message(file)\n",
        "    return msg.body\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"📄 Unstructured to Structured with Gemini\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload a file\", type=[\"pdf\", \"docx\", \"xlsx\", \"msg\", \"png\"])\n",
        "\n",
        "if uploaded_file:\n",
        "    file_type = uploaded_file.name.split('.')[-1].lower()\n",
        "\n",
        "    if file_type == \"pdf\":\n",
        "       raw_text = extract_text_from_pdf(uploaded_file)\n",
        "    elif file_type == \"docx\":\n",
        "       raw_text = extract_text_from_docx(uploaded_file)\n",
        "    elif file_type == \"xlsx\":\n",
        "       raw_text = extract_text_from_excel(uploaded_file)\n",
        "    elif file_type == \"msg\":\n",
        "       raw_text = extract_text_from_msg(uploaded_file)\n",
        "    elif file_type == \"png\":\n",
        "       raw_text = extract_text_from_image(uploaded_file)\n",
        "    else:\n",
        "        st.error(\"Unsupported file type\")\n",
        "        raw_text = \"\"\n",
        "\n",
        "    st.subheader(\"📜 Raw Text\")\n",
        "    st.text_area(\"Extracted\", raw_text, height=300)\n",
        "\n",
        "    if st.button(\"🔍 Extract Structured Data with Gemini\"):\n",
        "        structured = extract_structured_data_with_gemini(raw_text)\n",
        "        st.subheader(\"🗃️ Structured Output\")\n",
        "        st.code(structured, language=\"json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfR6zosxi4BD",
        "outputId": "76cfe875-ad5e-44ea-f3b0-9c3c8beb7b46"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import os\n",
        "\n",
        "# Kill any existing ngrok and streamlit processes\n",
        "!kill -9 $(ps -e | grep -e \"ngrok\" -e \"streamlit\" | awk '{print $1}')\n",
        "\n",
        "# Ensure the NGROK_TOKEN is set\n",
        "if not NGROK_TOKEN:\n",
        "    raise ValueError(\"Please provide your ngrok authentication token in the previous cell and run it again.\")\n",
        "\n",
        "# Authenticate ngrok\n",
        "ngrok.set_auth_token(NGROK_TOKEN)\n",
        "\n",
        "# Connect to the new tunnel\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"🔗 Public URL:\", public_url)\n",
        "\n",
        "!streamlit run app.py &> /dev/null &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INELuxMejAy0",
        "outputId": "6e1a7394-763b-40ed-d34a-27e58a1708a6"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔗 Public URL: NgrokTunnel: \"https://d7ded8f299d2.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfdfb93a"
      },
      "source": [
        "# Get your ngrok token from https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "NGROK_TOKEN = \"30lwBOq6bSavvKmbTVDkNftPax0_6vtyLW261wRFPMT1zbiS9\"  # @param {type:\"string\"}"
      ],
      "execution_count": 8,
      "outputs": []
    }
  ]
}